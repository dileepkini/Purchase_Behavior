{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T01:29:02.160558Z",
     "start_time": "2019-08-21T01:28:57.863119Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "from collections import deque\n",
    "% matplotlib inline\n",
    "\n",
    "# read in the json files\n",
    "portfolio = pd.read_json('data/portfolio.json', orient='records', lines=True)\n",
    "profile = pd.read_json('data/profile.json', orient='records', lines=True)\n",
    "transcript = pd.read_json('data/transcript.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T03:36:27.286653Z",
     "start_time": "2019-08-07T03:36:27.278192Z"
    }
   },
   "source": [
    "- offers were made on days 0,7,14,17,21,24\n",
    "- 75% of the population received offers each time offers were made\n",
    "    - `received.time.value_counts()/profile.shape[0]`\n",
    "- 75% of all the offers given were viewed\n",
    "    - `viewed.shape[0]/received.shape[0]`\n",
    "- at a given time a person received at most one offer\n",
    "    - `received.groupby('person')['time'].value_counts().value_counts()`\n",
    "- an person might receive the same offer multiple times over the course of 6 weeks\n",
    "    - `received.groupby('person')['id'].value_counts().value_counts()`\n",
    "- There are only 6 people who have not received a single offer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If these set of people recived an offer:\n",
    "- would they view it?\n",
    "    - if yes would it encourage/discourage them to complete the offer\n",
    "- would they have completed the offer \n",
    "- or to rephrase the question does viewing the offer have an effect on completing the offer\n",
    "- depends on the person and the type of offer (bogo, discount)\n",
    "- maybe someone will complete the offer only "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (view and complete) or (not view and complete) -> 1\n",
    "- does not view or does not complete -> 0\n",
    "- for each (offer, person) we can train a decision tree that tells us whether the person will view and complete the offer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business understanding (CRISP-DM Step 1)\n",
    "- In this project our goal will be to try and predict if we should show a given offer to a given customer\n",
    "- From a business perspective we want to show offers to those people who satisfy the following conditions\n",
    "    - who are likely to complete the offer if they viewed the offer\n",
    "    - who are not likely to complete the offer if they did not view the offer\n",
    "- The second condition is important because if a customer would complete the offer even without viewing it would mean we need to not have given them the offer in the first place, and starbucks could have saved revenue here.\n",
    "- If we can identify a subset of customers that satisfies both these conditions then by showing these individuals specific offers we can capture revenue that we would have otherwise missed out on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement:\n",
    "Our goal will be identify customers which show a strong positive relationship between viewing an offer and completing it. We will call such customer **responsive** customers.\n",
    "We will formulate this as a classification problem where a user will be given a positive label (called responsive) when either\n",
    "1. the user has completed the offer and viewed the offer OR\n",
    "2. the user has not completed the offer and not viewed the offer\n",
    "\n",
    "With such a labeling in place our attempt will be to come up with a classifier that predicts whether a customer is responsive based on the features from the customer and the offer being shown to them.\n",
    "\n",
    "### Strategy\n",
    "- We will begin with 3 different types of classifiers and conduct a preliminary analysis on their ability to perform the required classification\n",
    "- After evaluating the preliminary modeling stage we will pick one out of the 3 and perform a grid search to further optimize the solution\n",
    "\n",
    "### Metrics\n",
    "- In order to evaluate the performance of the classification model we will employ a F-beta score that gives more importance to precision as compared to recall.\n",
    "- This is because there is a cost associated with sending offers to unresponsive customers.\n",
    "    - An unresponsive customer might complete the offer without even seeing it, which means we could have saved money by not showing the customer this offer\n",
    "    - An unresposive cusomter might not complete the offer if they see it, which means the offer is negatively impacting their spending.\n",
    "- With this in mind we will want to minimize the False Positives and hence give more importance to precision rather than recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data understanding (CRISP-DM Step 2)\n",
    "- we have been given data regarding each user which we can make use of as features\n",
    "- starbucks has also provided is with transcripts regarding if/when a user viewed/completed their shown offers.\n",
    "- we can use this to figure out which users actually viewed their offers before completing their offers.\n",
    "    - we have to be careful here though, an offer that was viewed very early and an offer that was viewed late might have different effects on the behavior of the users\n",
    "    - For instance assume a user has completed \\$8 out of \\$10 required to complete an offer before seeing the offer. And if the offer has a reward of \\$4, then then the user might be compelled to go out and spend \\$2 to get a bigger reward. This should not let us bias our answer to say that the we should give such offers to those people.\n",
    "    - We should also be aware that we do not have control over when the user is going to view the offer.\n",
    "- looking at the type of offers that were completed we see that informational offers cannot be completed, since there is no difficulty/reward associated with them. \n",
    "    - So in order to evaluate whether an information offer was effective we will have to see if the individual performed some transaction in the duration corresponding to the informational offer\n",
    "- for bogo/discount orders difficulty/rewards are specified which we can use as features as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add some plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data Preparation  (CRISP-DM Step 3)\n",
    "- are there any missing values?\n",
    "    - the gender and income columns in the profile seem to be have missing values\n",
    "    - if a row is missing gender then it is missing income and vice versa\n",
    "    - we choose to drop these users out of our analysis\n",
    "    - another thing we observe is that there are users who have not been shown a single offer\n",
    "- are there any duplicate values?\n",
    "    - There are users who might receive the same offer twice, and both of them can be marked complete using a common set of transactions.\n",
    "- are there any categorical variables?\n",
    "    - the offers in the portfolios have channels and offer_type which we will convert into dummy variables\n",
    "- are there variables that need cleaning?\n",
    "    - each transaction type has a different type of value stored as a dict, we wil need to extract the data into separate columns\n",
    "    - since a user might be shown the same offer more than once, we need to make sure that we use the time columns to identify which offer receivals are related to which offer views and completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T01:29:03.030702Z",
     "start_time": "2019-08-21T01:29:02.162512Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def attach_dict_cols(df, event, col='value'):\n",
    "    \"\"\"\n",
    "    A helper function to clean the transactions data.\n",
    "    \n",
    "    Args:\n",
    "        df: A dataframe that contains all the transactions\n",
    "        event: the type of event we want to filter and clean. This should be one of the values in the 'event' column in df\n",
    "        col: The column which contains the dict describing the various attributes of this event\n",
    "    Returns:\n",
    "        A dataframe of the specific event with the dict in the value col transformed to separate columns.\n",
    "    \"\"\"\n",
    "    df = df[df['event'] == event].copy()\n",
    "    attributes = pd.DataFrame(list(df[col]), index=df.index)\n",
    "    attributes.columns = [col.replace(' ', '_') for col in attributes.columns]\n",
    "    df = pd.concat([df.drop('value', axis=1), attributes], axis=1, sort=False).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "transcript['transcript_id'] = np.arange(transcript.shape[0])\n",
    "received = attach_dict_cols(transcript, 'offer received')\n",
    "viewed = attach_dict_cols(transcript, 'offer viewed')\n",
    "completed = attach_dict_cols(transcript, 'offer completed')\n",
    "transaction = attach_dict_cols(transcript, 'transaction')\n",
    "\n",
    "#received.groupby('offer_id')['time'].value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T01:29:03.514228Z",
     "start_time": "2019-08-21T01:29:03.032819Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "portfolio['duration_hours'] = portfolio.duration * 24\n",
    "portfolio['offer_id'] = portfolio.id\n",
    "\n",
    "received['receive_id'] = transcript['transcript_id']\n",
    "received['time_receive'] = received['time']\n",
    "received = pd.merge(received, portfolio[['offer_id', 'duration_hours', 'offer_type', 'difficulty', 'channels']],\n",
    "                    on='offer_id') \n",
    "received['end_time'] = received['time'] + received.duration_hours\n",
    "\n",
    "viewed = pd.merge_asof(viewed, received[['person', 'time', 'offer_id', 'time_receive', 'receive_id']].sort_values('time'),\n",
    "                    by=['person', 'offer_id'], on='time')\n",
    "received = received.drop(['receive_id', 'time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T01:29:04.833816Z",
     "start_time": "2019-08-21T01:29:03.516613Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rc = pd.concat([received, completed], sort=False).sort_values('time')\n",
    "\n",
    "rec_dict = {person:{offer:deque() for offer in portfolio.id} for person in profile.id}\n",
    "\n",
    "# loop through all the receives and completes\n",
    "# each time you see a complete find the first receive of the same offer that is still open \n",
    "#rec_dict = person -> offer -> [(transcript_id, end_time)]\n",
    "complete_list = []\n",
    "for tup in (received.itertuples(index=False)):\n",
    "    rec_dict[tup.person][tup.offer_id].append((tup.transcript_id,tup.end_time))\n",
    "\n",
    "for tup in (completed.itertuples(index=False)):\n",
    "    stash = rec_dict[tup.person][tup.offer_id]\n",
    "    found = False\n",
    "    while stash and (not found):\n",
    "        rec = stash.popleft()\n",
    "        if rec[1] >= tup.time:\n",
    "            complete_list.append(rec[0])\n",
    "            found = True\n",
    "    if not found:\n",
    "        raise\n",
    "\n",
    "assert completed.shape[0] == len(complete_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T01:29:05.084865Z",
     "start_time": "2019-08-21T01:29:04.836773Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "completed['receive_id'] = complete_list\n",
    "\n",
    "received = received.merge(viewed[['receive_id', 'time']], left_on='transcript_id', right_on='receive_id', \n",
    "                          how='left', suffixes=('', '_view'))\n",
    "\n",
    "received = received.merge(completed[['receive_id', 'time']], left_on='transcript_id', right_on='receive_id',\n",
    "                         how='left', suffixes=('_view', '_complete'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T04:09:36.517447Z",
     "start_time": "2019-08-21T04:09:36.269724Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = received.copy()\n",
    "\n",
    "df['viewed'] = (~df.time_view.isnull())\n",
    "df['completed'] = (~df.time_complete.isnull())\n",
    "\n",
    "channels = set(x for list_ in portfolio.channels.values for x in list_)\n",
    "for channel in channels:\n",
    "    df[channel] = df.channels.apply(lambda _: (channel in _))\n",
    "\n",
    "df['offer_type_dummy'] = df['offer_type']\n",
    "df = pd.get_dummies(df, columns=['offer_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T04:09:36.681780Z",
     "start_time": "2019-08-21T04:09:36.556751Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>completed</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer_type_dummy</th>\n",
       "      <th>viewed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bogo</th>\n",
       "      <th>False</th>\n",
       "      <td>10614.0</td>\n",
       "      <td>11748.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>3921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">discount</th>\n",
       "      <th>False</th>\n",
       "      <td>9740.0</td>\n",
       "      <td>13440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>2893.0</td>\n",
       "      <td>4470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">informational</th>\n",
       "      <th>False</th>\n",
       "      <td>11449.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3786.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "completed                  False    True \n",
       "offer_type_dummy viewed                  \n",
       "bogo             False   10614.0  11748.0\n",
       "                 True     4216.0   3921.0\n",
       "discount         False    9740.0  13440.0\n",
       "                 True     2893.0   4470.0\n",
       "informational    False   11449.0      NaN\n",
       "                 True     3786.0      NaN"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['offer_type_dummy', 'viewed'])['completed'].value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T04:09:36.856482Z",
     "start_time": "2019-08-21T04:09:36.834879Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_profile = profile.dropna().copy()\n",
    "clean_profile['person'] = clean_profile['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T04:09:37.549843Z",
     "start_time": "2019-08-21T04:09:37.359975Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_profile = pd.get_dummies(clean_profile, columns=['gender'], prefix='gender')\n",
    "profile_cols = ['age', 'became_member_on', 'gender_M', 'gender_O', 'gender_F', 'income', 'person']\n",
    "#profile_cols = ['age', 'became_member_on', 'gender', 'income', 'person']\n",
    "\n",
    "df = pd.merge(df, clean_profile[profile_cols], on='person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T04:09:38.016563Z",
     "start_time": "2019-08-21T04:09:37.881995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>completed</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viewed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>25451</td>\n",
       "      <td>24319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>8606</td>\n",
       "      <td>8125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "completed  False  True \n",
       "viewed                 \n",
       "False      25451  24319\n",
       "True        8606   8125"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('viewed')['completed'].value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T04:09:38.524029Z",
     "start_time": "2019-08-21T04:09:38.516649Z"
    }
   },
   "outputs": [],
   "source": [
    "df['label'] = (df['viewed'] == df['completed']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T04:09:40.546702Z",
     "start_time": "2019-08-21T04:09:40.540865Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_cols = ['duration_hours', 'difficulty', 'mobile', 'social', 'email', 'web', \n",
    "            'offer_type_bogo', 'offer_type_discount', 'offer_type_informational', \n",
    "            'age', 'became_member_on', 'gender_M', 'gender_F', 'gender_O', 'income', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T04:09:46.860691Z",
     "start_time": "2019-08-21T04:09:46.810350Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[all_cols].copy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T04:10:18.100651Z",
     "start_time": "2019-08-21T04:10:18.079481Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df.offer_type_informational == 0].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling  (CRISP-DM Step 4)\n",
    "- In this section we will try and predict the labels for customers that have been shown an offer\n",
    "- the label we have assigned is positive when the customer completes and offer if and only if they have been seen the offer\n",
    "- We will split the data into training and test sets \n",
    "- we will then train a AdaBoostClassifier and evaluate its performance on unseen data, the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T02:02:16.558801Z",
     "start_time": "2019-08-22T02:02:16.548241Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T02:02:19.181468Z",
     "start_time": "2019-08-22T02:02:19.106610Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = df.drop('label', axis=1)\n",
    "labels = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    results['test_acc'] = accuracy_score(y_test, y_pred)\n",
    "    results['test_f'] = fbeta_score(y_test, y_pred, 0.5)\n",
    "    results['test_prec'] = precision_score(y_test, y_pred)\n",
    "    results['test_rec'] = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T02:15:58.365070Z",
     "start_time": "2019-08-22T02:15:58.317231Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    results = {}\n",
    "    learner.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    \n",
    "    training_pred = learner.predict(X_train[:1000])\n",
    "    results['train_acc'] = accuracy_score(y_train[:1000], training_pred)\n",
    "    results['train_f'] = fbeta_score(y_train[:1000], training_pred, 0.5)\n",
    "    results['train_prec'] = precision_score(y_train[:1000], training_pred)\n",
    "    results['train_rec'] = recall_score(y_train[:1000], training_pred)\n",
    "    \n",
    "    y_pred = learner.predict(X_test)\n",
    "    results['test_acc'] = accuracy_score(y_test, y_pred)\n",
    "    results['test_f'] = fbeta_score(y_test, y_pred, 0.5)\n",
    "    results['test_prec'] = precision_score(y_test, y_pred)\n",
    "    results['test_rec'] = recall_score(y_test, y_pred)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T02:28:57.036147Z",
     "start_time": "2019-08-22T02:28:57.026391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39900, 15)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T02:33:23.517867Z",
     "start_time": "2019-08-22T02:33:17.270677Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_1 = DecisionTreeClassifier()\n",
    "clf_2 = AdaBoostClassifier()\n",
    "clf_3 = GradientBoostingClassifier()\n",
    "clf_4 = RandomForestClassifier()\n",
    "\n",
    "sizes = [int(X_train.shape[0] * 0.02), int(X_train.shape[0]*0.2), X_train.shape[0]]\n",
    "results = {}\n",
    "for clf in [clf_1, clf_2, clf_3, clf_4]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i in sizes:\n",
    "        results[clf_name][i] = train_predict(clf, i, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T02:34:14.149163Z",
     "start_time": "2019-08-22T02:34:14.133393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AdaBoostClassifier': {798: {'test_acc': 0.59454176377715962,\n",
       "   'test_f': 0.50440352281825462,\n",
       "   'test_prec': 0.55607476635514019,\n",
       "   'test_rec': 0.367725321888412,\n",
       "   'train_acc': 0.64100000000000001,\n",
       "   'train_f': 0.55236270753512129,\n",
       "   'train_prec': 0.60278745644599308,\n",
       "   'train_rec': 0.4138755980861244},\n",
       "  7980: {'test_acc': 0.61544244793624536,\n",
       "   'test_f': 0.54357788155195741,\n",
       "   'test_prec': 0.58309925093632964,\n",
       "   'test_rec': 0.42763948497854076,\n",
       "   'train_acc': 0.60899999999999999,\n",
       "   'train_f': 0.51222351571594871,\n",
       "   'train_prec': 0.54153846153846152,\n",
       "   'train_rec': 0.42105263157894735},\n",
       "  39900: {'test_acc': 0.62386286745357489,\n",
       "   'test_f': 0.55986855617169851,\n",
       "   'test_prec': 0.58876889848812097,\n",
       "   'test_rec': 0.46798283261802576,\n",
       "   'train_acc': 0.59499999999999997,\n",
       "   'train_f': 0.50267379679144386,\n",
       "   'train_prec': 0.51790633608815428,\n",
       "   'train_rec': 0.44976076555023925}},\n",
       " 'DecisionTreeClassifier': {798: {'test_acc': 0.53725283813247127,\n",
       "   'test_f': 0.45737772606133403,\n",
       "   'test_prec': 0.46829362029208299,\n",
       "   'test_rec': 0.41836909871244637,\n",
       "   'train_acc': 0.91200000000000003,\n",
       "   'train_f': 0.90325765054294171,\n",
       "   'train_prec': 0.91044776119402981,\n",
       "   'train_rec': 0.87559808612440193},\n",
       "  7980: {'test_acc': 0.53484700398466278,\n",
       "   'test_f': 0.46808657530463593,\n",
       "   'test_prec': 0.46871759419287934,\n",
       "   'test_rec': 0.46557939914163088,\n",
       "   'train_acc': 0.98799999999999999,\n",
       "   'train_f': 0.99412340842311442,\n",
       "   'train_prec': 1.0,\n",
       "   'train_rec': 0.9712918660287081},\n",
       "  39900: {'test_acc': 0.53920757837756561,\n",
       "   'test_f': 0.47035878694170152,\n",
       "   'test_prec': 0.47313538352774831,\n",
       "   'test_rec': 0.45957081545064377,\n",
       "   'train_acc': 0.94899999999999995,\n",
       "   'train_f': 0.97003154574132511,\n",
       "   'train_prec': 0.99460916442048519,\n",
       "   'train_rec': 0.88277511961722488}},\n",
       " 'GradientBoostingClassifier': {798: {'test_acc': 0.58867754304187658,\n",
       "   'test_f': 0.49066445668600406,\n",
       "   'test_prec': 0.54820261437908502,\n",
       "   'test_rec': 0.34557939914163088,\n",
       "   'train_acc': 0.76300000000000001,\n",
       "   'train_f': 0.74290998766954386,\n",
       "   'train_prec': 0.80066445182724255,\n",
       "   'train_rec': 0.57655502392344493},\n",
       "  7980: {'test_acc': 0.61153296744605667,\n",
       "   'test_f': 0.5325457493629836,\n",
       "   'test_prec': 0.583502538071066,\n",
       "   'test_rec': 0.39467811158798283,\n",
       "   'train_acc': 0.64800000000000002,\n",
       "   'train_f': 0.56491885143570542,\n",
       "   'train_prec': 0.61148648648648651,\n",
       "   'train_rec': 0.43301435406698563},\n",
       "  39900: {'test_acc': 0.62348695586797986,\n",
       "   'test_f': 0.55589189189189192,\n",
       "   'test_prec': 0.5944508670520231,\n",
       "   'test_rec': 0.44137339055793989,\n",
       "   'train_acc': 0.61799999999999999,\n",
       "   'train_f': 0.52601156069364163,\n",
       "   'train_prec': 0.55487804878048785,\n",
       "   'train_rec': 0.4354066985645933}},\n",
       " 'RandomForestClassifier': {798: {'test_acc': 0.55845425156003303,\n",
       "   'test_f': 0.44059236012357189,\n",
       "   'test_prec': 0.49341021416803954,\n",
       "   'test_rec': 0.30849785407725322,\n",
       "   'train_acc': 0.89200000000000002,\n",
       "   'train_f': 0.89798087141339011,\n",
       "   'train_prec': 0.92349726775956287,\n",
       "   'train_rec': 0.80861244019138756},\n",
       "  7980: {'test_acc': 0.55867979851139016,\n",
       "   'test_f': 0.4684436657906812,\n",
       "   'test_prec': 0.4950407758430681,\n",
       "   'test_rec': 0.38557939914163092,\n",
       "   'train_acc': 0.95999999999999996,\n",
       "   'train_f': 0.96116027531956738,\n",
       "   'train_prec': 0.96782178217821779,\n",
       "   'train_rec': 0.93540669856459335},\n",
       "  39900: {'test_acc': 0.56416810766107817,\n",
       "   'test_f': 0.48613541788200521,\n",
       "   'test_prec': 0.50281576830249397,\n",
       "   'test_rec': 0.42918454935622319,\n",
       "   'train_acc': 0.93400000000000005,\n",
       "   'train_f': 0.93406593406593419,\n",
       "   'train_prec': 0.94444444444444442,\n",
       "   'train_rec': 0.89473684210526316}}}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt36]",
   "language": "python",
   "name": "conda-env-pt36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
